= Setup a local Chronix Spark cluster within 5 minutes on Mac OS X or Linux
This document describes how to setup a local Chronix cluster. The cluster
consists of a local Spark Cluster und a local Solr Cloud containing test data.

== Prerequisites
 * Download and uncompress the software package directly into `chronix-infrastructure-local` directory.
 There should be the dirs `solr-cloud` and `spark` in this directory afterwards. The download URL is:
https://storage.googleapis.com/chronix-spark/chronix-local-pkg-0.3.tar.gz (do not add the download time to the 5mins ;-)
 * `chmod 777` the `*.sh` files

== Start the local cluster
 * Start Solr Cloud with `./startSolrCloud.sh`
 * Start Spark Cluster with `./startSparkCluster.sh`
 * (optional) Start Zeppelin with `./startZeppelin.sh`
 * After that you've a running Chronix cluster with test data inside. You can use Zeppelin to perform data analysis. A Chronix Spark sample notebook can be found link:https://github.com/ChronixDB/chronix.spark/blob/master/chronix-infrastructure-local/Chronix%20Spark%20Samples.json[here]. Just import it into Zeppelin and play.
 * If you want to import your own data set then you can use the link:https://github.com/ChronixDB/chronix.examples/tree/master/chronix-importer[Chronix Importer]
 

== Endpoints

After starting the cluster the following endpoints should be availabe:

 * Solr Cloud Node 1: http://localhost:8983/solr
 * Solr Cloud Node 2: http://localhost:7574/solr
 * Zookeeper: http://localhost:9983
 * Spark Master Web UI: http://localhost:8988
 * (optional) Zeppelin Web UI: http://localhost:8991/#/

== Cluster stats
 * Solr Cloud: 2 Nodes, 4 Shards, 8,707 time series, 76,983,735 observations (JMX & Unix metrics)
 * Spark Cluster: 1 Master, 1 Worker

== Shut down the local cluster
 * Stop Solr Cloud with `./stopSolrCloud.sh`
 * Stop Spark Cluster with `./stopSparkCluster.sh`
 * (optional) Stop Zeppelin with `./stopZeppelin.sh`
